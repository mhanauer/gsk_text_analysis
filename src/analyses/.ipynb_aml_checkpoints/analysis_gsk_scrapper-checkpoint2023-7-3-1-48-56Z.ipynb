{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%load_ext lab_black"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step: Load data"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import nltk\n",
        "from pyprojroot import here\n",
        "\n",
        "from skimpy import clean_columns\n",
        "from data_cleaning.fun_hot_encode_limit import fun_hot_encode_limit\n",
        "\n",
        "path_data = here(\"./data\")\n",
        "os.chdir(path_data)\n",
        "data_ra = pd.read_csv(\"ra_data.csv\")\n",
        "data_ra = clean_columns(data_ra)\n",
        "\n",
        "nltk.download(\"vader_lexicon\")\n",
        "data_ra[\"date\"] = pd.to_datetime(data_ra[\"date\"])"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1;36m11\u001b[0m column names have been cleaned\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> column names have been cleaned\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "[nltk_data] Downloading package vader_lexicon to\n[nltk_data]     /home/azureuser/nltk_data...\n[nltk_data]   Package vader_lexicon is already up-to-date!\n/tmp/ipykernel_5494/814015519.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n  data_ra[\"date\"] = pd.to_datetime(data_ra[\"date\"])\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1691010956243
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from pyppeteer import launch\n",
        "import json\n",
        "\n",
        "async def main():\n",
        "    browser = await launch()\n",
        "    page = await browser.newPage()\n",
        "    await page.goto('https://reviews.webmd.com/drugs/drugreview-6968-paxil-oral')\n",
        "\n",
        "    # wait for the JSON data to load\n",
        "    await page.waitForSelector('body')\n",
        "\n",
        "    # extract the raw HTML\n",
        "    body = await page.evaluate('() => document.body.innerHTML')\n",
        "\n",
        "    # find the script tag containing the JSON data\n",
        "    script_tag = body[body.find('drug_review_nimvs'):]\n",
        "\n",
        "    # extract and parse the JSON data\n",
        "    json_str = script_tag[script_tag.index('{'):script_tag.rindex('}')+1]\n",
        "    data = json.loads(json_str)\n",
        "\n",
        "    # print the reviews\n",
        "    for review in data['drug_review_nimvs'][0]['review_nimvs']:\n",
        "        print(review['UserExperience'])\n",
        "\n",
        "    await browser.close()\n",
        "\n",
        "asyncio.get_event_loop().run_until_complete(main())\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "The version of firefox cannot be detected. Trying with latest driver version\n"
        },
        {
          "output_type": "error",
          "ename": "NoSuchDriverException",
          "evalue": "Message: Unable to obtain driver for firefox using Selenium Manager.; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/selenium/webdriver/common/driver_finder.py:38\u001b[0m, in \u001b[0;36mDriverFinder.get_path\u001b[0;34m(service, options)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 38\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[43mSeleniumManager\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdriver_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m path\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/selenium/webdriver/common/selenium_manager.py:97\u001b[0m, in \u001b[0;36mSeleniumManager.driver_location\u001b[0;34m(self, options)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(options\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_location\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 97\u001b[0m     \u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_location\u001b[49m \u001b[38;5;241m=\u001b[39m browser_path\n\u001b[1;32m     98\u001b[0m     options\u001b[38;5;241m.\u001b[39mbrowser_version \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# if we have the binary location we no longer need the version\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/selenium/webdriver/firefox/options.py:72\u001b[0m, in \u001b[0;36mOptions.binary_location\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mBINARY_LOCATION_ERROR)\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary\u001b[49m \u001b[38;5;241m=\u001b[39m value\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/selenium/webdriver/firefox/options.py:57\u001b[0m, in \u001b[0;36mOptions.binary\u001b[0;34m(self, new_binary)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(new_binary, FirefoxBinary):\n\u001b[0;32m---> 57\u001b[0m     new_binary \u001b[38;5;241m=\u001b[39m \u001b[43mFirefoxBinary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_binary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_binary \u001b[38;5;241m=\u001b[39m new_binary\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/selenium/webdriver/firefox/firefox_binary.py:48\u001b[0m, in \u001b[0;36mFirefoxBinary.__init__\u001b[0;34m(self, firefox_path, log_file)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_cmd:\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_cmd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_firefox_start_cmd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_cmd\u001b[38;5;241m.\u001b[39mstrip():\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/selenium/webdriver/firefox/firefox_binary.py:179\u001b[0m, in \u001b[0;36mFirefoxBinary._get_firefox_start_cmd\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;66;03m# couldn't find firefox on the system path\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    180\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find firefox in your system PATH.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    181\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please specify the firefox binary location or install firefox\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    182\u001b[0m         )\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m start_cmd\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Could not find firefox in your system PATH. Please specify the firefox binary location or install firefox",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mNoSuchDriverException\u001b[0m                     Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://reviews.webmd.com/drugs/drugreview-6968-paxil-oral\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Create a new instance of the Firefox driver\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m driver \u001b[38;5;241m=\u001b[39m \u001b[43mwebdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFirefox\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Go to the page\u001b[39;00m\n\u001b[1;32m     10\u001b[0m driver\u001b[38;5;241m.\u001b[39mget(url)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/selenium/webdriver/firefox/webdriver.py:59\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[0;34m(self, options, service, keep_alive)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice \u001b[38;5;241m=\u001b[39m service \u001b[38;5;28;01mif\u001b[39;00m service \u001b[38;5;28;01melse\u001b[39;00m Service()\n\u001b[1;32m     57\u001b[0m options \u001b[38;5;241m=\u001b[39m options \u001b[38;5;28;01mif\u001b[39;00m options \u001b[38;5;28;01melse\u001b[39;00m Options()\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice\u001b[38;5;241m.\u001b[39mpath \u001b[38;5;241m=\u001b[39m \u001b[43mDriverFinder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_path\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mservice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m     62\u001b[0m executor \u001b[38;5;241m=\u001b[39m FirefoxRemoteConnection(\n\u001b[1;32m     63\u001b[0m     remote_server_addr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice\u001b[38;5;241m.\u001b[39mservice_url,\n\u001b[1;32m     64\u001b[0m     ignore_proxy\u001b[38;5;241m=\u001b[39moptions\u001b[38;5;241m.\u001b[39m_ignore_local_proxy,\n\u001b[1;32m     65\u001b[0m     keep_alive\u001b[38;5;241m=\u001b[39mkeep_alive,\n\u001b[1;32m     66\u001b[0m )\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/selenium/webdriver/common/driver_finder.py:41\u001b[0m, in \u001b[0;36mDriverFinder.get_path\u001b[0;34m(service, options)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m     40\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to obtain driver for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptions\u001b[38;5;241m.\u001b[39mcapabilities[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbrowserName\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m using Selenium Manager.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NoSuchDriverException(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Path(path)\u001b[38;5;241m.\u001b[39mis_file():\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NoSuchDriverException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to locate or obtain driver for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptions\u001b[38;5;241m.\u001b[39mcapabilities[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbrowserName\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mNoSuchDriverException\u001b[0m: Message: Unable to obtain driver for firefox using Selenium Manager.; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location\n"
          ]
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1691011619147
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = \"https://reviews.webmd.com/drugs/drugreview-6968-paxil-oral\"\n",
        "\n",
        "response = requests.get(url)\n",
        "\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "reviews = soup.find_all('div', class_='your-class') # replace 'your-class' with the class that contains reviews\n",
        "\n",
        "for review in reviews:\n",
        "    print(review.text)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"wordnet\")\n",
        "\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "\n",
        "# Function to preprocess text\n",
        "def preprocess_text(text):\n",
        "    # Lowercase the text\n",
        "    text = text.lower()\n",
        "    # Tokenize the text\n",
        "    word_tokens = word_tokenize(text)\n",
        "    # Remove stopwords and lemmatize\n",
        "    filtered_text = [\n",
        "        lemmatizer.lemmatize(word) for word in word_tokens if word not in stop_words\n",
        "    ]\n",
        "    return \" \".join(filtered_text)\n",
        "\n",
        "\n",
        "# Preprocess the reviews\n",
        "data_ra[\"reviews_clean\"] = (\n",
        "    data_ra[\"reviews\"].apply(preprocess_text).values\n",
        ")\n",
        "\n",
        "data_ra.to_csv(\"data_ra_sentiment.csv\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Let's assume your DataFrame is called df and the column with the text data is 'reviews'\n",
        "data_ra[\"sentiment_scores\"] = data_ra[\"reviews\"].apply(\n",
        "    lambda review: sia.polarity_scores(review)\n",
        ")\n",
        "\n",
        "# The above will return a dictionary with 'compound', 'neg', 'neu', 'pos' as keys.\n",
        "# If you're interested in overall sentiment, you could use 'compound' score which is computed by summing the valence scores of each word in the lexicon, adjusted according to the rules, and then normalized to be between -1 (most extreme negative) and +1 (most extreme positive).\n",
        "# You can create a new column for this score.\n",
        "\n",
        "data_ra[\"compound_score\"] = data_ra[\"sentiment_scores\"].apply(\n",
        "    lambda score_dict: score_dict[\"compound\"]\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1690988318975
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Initialize the zero-shot classification pipeline\n",
        "classifier = pipeline(\"zero-shot-classification\")\n",
        "\n",
        "# Define the candidate labels\n",
        "candidate_labels = [\"pain management\"]\n",
        "\n",
        "\n",
        "# Function to apply the classifier to a review\n",
        "def classify_review(review):\n",
        "    result = classifier(review, candidate_labels)\n",
        "    return dict(zip(result[\"labels\"], result[\"scores\"]))\n",
        "\n",
        "\n",
        "# Apply the classifier to each review\n",
        "data_ra[\"emotion_scores\"] = data_ra[\"reviews\"].apply(\n",
        "    classify_review\n",
        ")\n",
        "\n",
        "# Create a new column for each label\n",
        "for label in candidate_labels:\n",
        "    data_ra[label] = data_ra[\"emotion_scores\"].apply(\n",
        "        lambda scores: scores.get(label)\n",
        "    )"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading:   0%|          | 0.00/1.13k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83a0e1cf539b4d6984b1e7f350eb3d46"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading:   0%|          | 0.00/1.52G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "40121173f1d34829b763b0a17c531fe6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa08a1746ded49d994d113b193df5246"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "77890596eb344e03a5e5059cca3d3f43"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dbc30e8cf7e145f58013f3c027209226"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2595830914e47c0a461de01d19dc999"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": 42,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1690991161336
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_ra_sentiment = clean_columns(data_ra)\n",
        "len_pain = (\n",
        "    data_ra_sentiment.query(\"pain_management >= .75\").reset_index(drop=True).shape[0]\n",
        ")\n",
        "len_all = data_ra_sentiment.shape[0]\n",
        "percent_pain = round(len_pain / len_all, 2)\n",
        "data_pain = pd.DataFrame(\n",
        "    {\"len_pain\": len_pain, \"len_all\": len_all, \"percent_pain\": percent_pain}, index=[0]\n",
        ")\n",
        "\n",
        "data_pain"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1;36m0\u001b[0m column names have been cleaned\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> column names have been cleaned\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 50,
          "data": {
            "text/plain": "   len_pain  len_all  percent_pain\n0        92      185           0.5",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>len_pain</th>\n      <th>len_all</th>\n      <th>percent_pain</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>92</td>\n      <td>185</td>\n      <td>0.5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 50,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1690991443392
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_ra_pain = data_ra_sentiment.query(\"pain_management >= .75\").reset_index(drop=True)"
      ],
      "outputs": [],
      "execution_count": 57,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1690992116997
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from bertopic import BERTopic\n",
        "\n",
        "# Download the necessary NLTK data\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"wordnet\")\n",
        "\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "# Add custom words to stop words\n",
        "custom_stop_words = [\"humira\", \"syringe\", \"kit\", \"pen\", \"injector\"]\n",
        "stop_words.update(custom_stop_words)\n",
        "\n",
        "# Initialize the lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "\n",
        "# Function to preprocess text\n",
        "def preprocess_text(text):\n",
        "    # Lowercase the text\n",
        "    text = text.lower()\n",
        "    # Tokenize the text\n",
        "    word_tokens = word_tokenize(text)\n",
        "    # Remove stopwords and lemmatize\n",
        "    filtered_text = [\n",
        "        lemmatizer.lemmatize(word) for word in word_tokens if word not in stop_words\n",
        "    ]\n",
        "    return \" \".join(filtered_text)\n",
        "\n",
        "\n",
        "# Preprocess the reviews\n",
        "reviews = data_ra_pain[\"reviews_clean\"].apply(preprocess_text).values\n",
        "\n",
        "# Create BERTopic model\n",
        "topic_model = BERTopic(language=\"english\")\n",
        "\n",
        "# Fit the model to the reviews\n",
        "topics, _ = topic_model.fit_transform(reviews)\n",
        "\n",
        "# Get the topic frequencies\n",
        "topic_info = topic_model.get_topic_info()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "[nltk_data] Downloading package punkt to /home/azureuser/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to\n[nltk_data]     /home/azureuser/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to\n[nltk_data]     /home/azureuser/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n"
        }
      ],
      "execution_count": 65,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1690992436442
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic_info"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 70,
          "data": {
            "text/plain": "   Topic  Count                        Name  \\\n0     -1     29  -1_pain_ve_injection_month   \n1      0     49    0_pain_year_injection_ra   \n2      1     14     1_sting_great_pain_year   \n\n                                      Representation  \\\n0  [pain, ve, injection, month, nt, year, taking,...   \n1  [pain, year, injection, ra, life, nt, methotre...   \n2  [sting, great, pain, year, using, painful, fla...   \n\n                                 Representative_Docs  \n0  [since january 2009 taking without mtx taking ...  \n1  [diagnosed 4 year ago started methotrexate emb...  \n2  ['ve using 3 year . made remarkable improvemen...  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Topic</th>\n      <th>Count</th>\n      <th>Name</th>\n      <th>Representation</th>\n      <th>Representative_Docs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1</td>\n      <td>29</td>\n      <td>-1_pain_ve_injection_month</td>\n      <td>[pain, ve, injection, month, nt, year, taking,...</td>\n      <td>[since january 2009 taking without mtx taking ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>49</td>\n      <td>0_pain_year_injection_ra</td>\n      <td>[pain, year, injection, ra, life, nt, methotre...</td>\n      <td>[diagnosed 4 year ago started methotrexate emb...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>14</td>\n      <td>1_sting_great_pain_year</td>\n      <td>[sting, great, pain, year, using, painful, fla...</td>\n      <td>['ve using 3 year . made remarkable improvemen...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 70,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1690993111314
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}